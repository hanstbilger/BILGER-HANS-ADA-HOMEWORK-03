---
title: "BILGER-HANS-ADA-HOMEWORK-03"
author: "Hans Bilger"
date: "March 25, 2019"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##Problem 1

```{r}
####Write a simple R function you call Z.prop.test(), that can perform one- or two-sample Z-tests for proportion data, using the following guidelines.

####Your function should take the following arguments: p1 and n1 (no default) representing the estimated proportion and sample size (e.g., based on your sample data); p2 and n2 (both defaulting to NULL) that contain a second sample’s proportion and sample size data in the event of a two-sample test; p0 (no default) as the expected value for the population proportion; and alternative (default “two.sided”) and conf.level (default 0.95), to be used in the same way as in the function t.test().

####When conducting a two-sample test, it should be p1 that is tested as being smaller or larger than p2 when alternative=“less” or alternative=“greater”, respectively, the same as in the use of x and y in the function t.test().

####The function should perform a one-sample Z-test using p1, n1, and p0 if either p2 or n2 (or both) is NULL.

####The function should contain a check for the rules of thumb we have talked about (n×π>5 and n×(1−π)>5) to ensure the validity of assuming the normal distribution in both the one- and two-sample settings. If this is violated, the function should still complete, but it should also print an appropriate warning message.

####The function should return a list containing the following elements: Z (the test statistic), P (the appropriate p value), and CI (the two-sided CI with respect to “conf.level” around p1 in the case of a one-sample test and around p2-p1 in the case of a two-sample test). For all test alternatives (“two.sided”, “greater”, “less”), calculate symmetric CIs based on quantiles of the normal distribution rather than worrying about calculating single-limit confidence bounds.

Z.prop.test <- function(p0, p1, p2, n1, n2, alternative="two.sided", conf.level=0.95) {
  if((n1 * p0 > 5) & (n1 * (1-p0) >5)) {
    print("Either n1 * p0 > 5 or n* (1-p0) >5. Because of this, it may be invalid to assume the normal     distribution.")
    }
  if(is.null(p2) | is.null(n2)) {
z <- (p1 - p0)/sqrt(p0 * (1 - p0)/n1)
print(paste0("Z = ", z))
p <- pnorm(z, lower.tail = TRUE)
print(paste0("p-value =", p, sep=' '))
lower <- p1 - qnorm(1-(1-conf.level)/2) * sqrt(p1 * (1 - p1)/n1)
upper <- p1 + qnorm(1-(1-conf.level)/2) * sqrt(p1 * (1 - p1)/n1)
ci <- c(lower, upper)
print(paste0("confidence interval = ", lower, ", ", upper))
  if(alternative=="greater") {
    print("alternative hypothesis: true p1 is greater than ", p0)
  }
  if(alternative=="less") {
    print("alternative hypothesis: true p1 is less than ", p0)
  }
  if(alternative=="two.sided") {
    print("alternative hypothesis: true p1 is greater or less than ", p0)
  }
  } else {
pstar <- p1*(n1/(n1+n2)) + p2*(n1/(n1+n2))
z <- (p2 - p1)/sqrt(pstar * (1 - pstar)) * (1/n1 + 1/n2)
print(paste0("Z = ", z))
p.upper <- 1 - pnorm(z, lower.tail = TRUE)
p.lower <- pnorm(z, lower.tail = FALSE)  # two-tailed probability, so we add the upper and lower tails
p <- p.upper + p.lower
print(paste0("p-value = ", p))
lower <- (p2-p1) - qnorm(1-(1-conf.level)/2) * sqrt(p1 * (1 - p1)/n1)
upper <- (p2-p1) + qnorm(1-(1-conf.level)/2) * sqrt(p1 * (1 - p1)/n1)
ci <- c(lower, upper)
ci
print(paste0("confidence interval = ", lower, ", ", upper))
  if(alternative=="greater") {
    print("alternative hypothesis: true p1 is greater than p2")
  }
  if(alternative=="less") {
    print("alternative hypothesis: true p1 is less than p2")
  }
  if(alternative=="two.sided") {
    print("alternative hypothesis: true p1 is greater or less than p2")
    }
  }
}


Z.prop.test(.7, .5, .6, 1000, 2000)
  
```

```{r}
p1 <- 0.6
p0 <- 0.8
n1 <- 30

z <- (p1 - p0)/sqrt(p0 * (1 - p0)/n1)
z
p <- pnorm(z, lower.tail = TRUE)
p
lower <- p1 - qnorm(0.975) * sqrt(p1 * (1 - p1)/n1)
upper <- p1 + qnorm(0.975) * sqrt(p1 * (1 - p1)/n1)
ci <- c(lower, upper)
ci

pt <- prop.test(x = 18, n = 30, p = 0.80, conf.level = 0.95, alternative = "less", 
    correct = FALSE)  # use correct=FALSE if we satisfy that n*pi and n*(1-pi) are both >5
pt
```

##Problem 2

```{r}
####The comparative primate dataset we have used from Kamilar and Cooper has in it a large number of variables related to life history and body size. For this exercise, the end aim is to fit a simple linear regression model to predict longevity (MaxLongevity_m) measured in months from species’ brain size (Brain_Size_Species_Mean) measured in grams. Do the following for both longevity~brain size and log(longevity)~log(brain size).

library(readr)
library(tidyverse)
library(manipulate)
library(cowplot)
f <- "https://raw.githubusercontent.com/difiore/ADA-2019/master/KamilarAndCooperData.csv"
d <- read_csv(f, col_names = TRUE)
head(d)
df <- d %>% select(MaxLongevity_m, Brain_Size_Species_Mean)
df <- df %>% drop_na
Longevity <- df$MaxLongevity_m
df$lnLongevity <- log(Longevity)
lnLongevity <- df$lnLongevity
BrainSize <- df$Brain_Size_Species_Mean
df$lnBrainSize <- log(BrainSize)
lnBrainSize <- df$lnBrainSize
```

```{r}
####Fit the regression model and, using {ggplot2}, produce a scatterplot with the fitted line superimposed upon the data. Append the the fitted model equation to your plot (HINT: use the function geom_text()).

##### Basic regression equations
m <- lm(Longevity ~ BrainSize, data = df)
summary(m)

lnm <- lm(lnLongevity ~ lnBrainSize, data = df)
lnm

##### Equation labels
m_eqn <- function(df){
    m <- lm(Longevity ~ BrainSize, data = df);
    eq <- substitute(italic(y) == a + b %.% italic(x),
         list(a = format(coef(m)[1], digits = 5),
              b = format(coef(m)[2], digits = 4)));
    as.character(as.expression(eq));
}

lnm_eqn <- function(df){
    lnm <- lm(lnLongevity ~ lnBrainSize, data = df);
    lneq <- substitute(italic(y) == a + b %.% italic(x),
         list(a = format(coef(lnm)[1], digits = 5),
              b = format(coef(lnm)[2], digits = 4)));
    as.character(as.expression(lneq));
}

##### Longevity ~ Brain Size scatterplot, with equation
g <- ggplot(data = df, aes(x = BrainSize, y = Longevity)) +
  geom_point() +
  geom_smooth(se=FALSE, show.legend = TRUE, method = lm) +
  geom_text(x = 150, y = 800, label = m_eqn(df), parse = TRUE)
g

##### ln(Longevity) ~ ln(Brain Size) plot, with equation
lng <- ggplot(data = df, aes(x = lnBrainSize, y = lnLongevity)) +
  geom_point() +
  geom_smooth(se=FALSE, show.legend = TRUE, method = lm) +
  geom_text(x = 2, y = 6.5, label = lnm_eqn(df), parse = TRUE)
lng

```


```{r}
####Identify and interpret the point estimate of the slope (β1), as well as the outcome of the test associated with the hypotheses H0: β1=0; HA: β1≠0. Also, find a 90% CI for the slope (β1) parameter.

beta1 <- cov(Longevity, BrainSize)/var(BrainSize)
beta1

lnbeta1 <- cov(lnLongevity, lnBrainSize)/var(lnBrainSize)
lnbeta1
##### The point estimate of the slope is 1.218. If significant, that for every unit of brain size increase (i.e. 1 gram), longevity will increase by 1.218 units (i.e. 1.218 days).

summary(m)
t <- coef(summary(m))
t <- data.frame(unlist(t))
colnames(t) <- c("Est", "SE", "t", "p")
t$calct <- (t$Est - 0)/t$SE
t$calct
t$calcp <- 2 * pt(t$calct, df = 126, lower.tail = FALSE)
t
alpha <- 0.05
t$lmCI <- confint(m, level = 1 - alpha) 

t.test(x=t$Est, mu=0, alternative='two.sided')


summary(lnm)
t <- coef(summary(lnm))
t <- data.frame(unlist(t))
colnames(t) <- c("Est", "SE", "t", "p")
t$calct <- (t$Est - 0)/t$SE
t$calct
t$calcp <- 2 * pt(t$calct, df = 126, lower.tail = FALSE)
t
alpha <- 0.05
t$lmCI <- confint(m, level = 1 - alpha) 

t.test(x=t$Est, mu=0, alternative='two.sided')
```


```{r}
####Using your model, add lines for the 90% confidence and prediction interval bands on the plot, and add a legend to differentiate between the lines.
m <- lm(data = df, Longevity ~ BrainSize)
h_hat <- predict(m, newdata = data.frame(BS = BrainSize))
df2 <- data.frame(cbind(BrainSize, Longevity, h_hat))
names(df2) <- c("x", "y", "yhat")
head(df2)

ci <- predict(m, newdata = data.frame(BS = BrainSize), interval = "confidence", 
    level = 0.90)  # for a vector of values
head(ci)

df2 <- cbind(df2, ci)
head(df2)
names(df2) <- c("x", "y", "yhat", "CIfit", "CIlwr", "CIupr")
head(df2)

#### ln version
lnm <- lm(data = df, lnLongevity ~ lnBrainSize)
h_hat <- predict(lnm, newdata = data.frame(BS = lnBrainSize))

lndf2 <- data.frame(cbind(lnBrainSize, lnLongevity, h_hat))
names(lndf2) <- c("x", "y", "yhat")
head(lndf2)

ci <- predict(lnm, newdata = data.frame(BS = lnBrainSize), interval = "confidence", 
    level = 0.90)  # for a vector of values
head(ci)

lndf2 <- cbind(lndf2, ci)
head(lndf2)
names(lndf2) <- c("x", "y", "yhat", "CIfit", "CIlwr", "CIupr")
head(lndf2)


##### Graph of 90% confidence interval

g <- ggplot(data = df2, aes(x = BrainSize, y = Longevity))
g <- g + geom_point(alpha = .1)
g <- g + geom_line(aes(x = BrainSize, y = CIfit), colour = "black")
g <- g + geom_line(aes(x = BrainSize, y = CIlwr), colour = "blue")
g <- g + geom_line(aes(x = BrainSize, y = CIupr), colour = "blue")
g

#### ln version
lng <- ggplot(data = lndf2, aes(x = lnBrainSize, y = lnLongevity))
lng <- lng + geom_point(alpha = .1)
lng <- lng + geom_line(aes(x = lnBrainSize, y = CIfit), colour = "black")
lng <- lng + geom_line(aes(x = lnBrainSize, y = CIlwr), colour = "blue")
lng <- lng + geom_line(aes(x = lnBrainSize, y = CIupr), colour = "blue")
lng

##### 90% prediction interval
pi <- predict(m, newdata = data.frame(BS = BrainSize), interval = "prediction", 
    level = 0.95)  # for a vector of values
head(pi)

df2 <- cbind(df2, pi)
head(df2)
names(df2) <- c("x", "y", "yhat", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr", 
    "PIupr")
head(df2)

#### ln version
lnpi <- predict(lnm, newdata = data.frame(BS = lnBrainSize), interval = "prediction", 
    level = 0.95)  # for a vector of values
head(lnpi)

lndf2 <- cbind(lndf2, lnpi)
head(lndf2)
names(lndf2) <- c("x", "y", "yhat", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr", 
    "PIupr")
head(lndf2)

#####graph of 90% confidence (blue) and prediction (red) intervals
g <- ggplot(data = df2, aes(x = BrainSize, y = Longevity))
g <- g + geom_point()
g <- g + geom_line(aes(x = BrainSize, y = CIfit), colour = "black")
g <- g + geom_line(aes(x = BrainSize, y = CIlwr), colour = "blue")
g <- g + geom_line(aes(x = BrainSize, y = CIupr), colour = "blue")
g <- g + geom_line(data = df2, aes(x = BrainSize, y = PIlwr), colour = "red")
g <- g + geom_line(data = df2, aes(x = BrainSize, y = PIupr), colour = "red")
g <- g + geom_text(x = 200, y = 1000, label = "black = fit, blue = confidence interval, red = predicition interval")
g

#### ln version
lng <- ggplot(data = lndf2, aes(x = lnBrainSize, y = lnLongevity))
lng <- lng + geom_point()
lng <- lng + geom_line(aes(x = lnBrainSize, y = CIfit), colour = "black")
lng <- lng + geom_line(aes(x = lnBrainSize, y = CIlwr), colour = "blue")
lng <- lng + geom_line(aes(x = lnBrainSize, y = CIupr), colour = "blue")
lng <- lng + geom_line(data = lndf2, aes(x = lnBrainSize, y = PIlwr), colour = "red")
lng <- lng + geom_line(data = lndf2, aes(x = lnBrainSize, y = PIupr), colour = "red")
lng <- lng + geom_text(x = 3, y = 6.7, label = "black = fit, blue = confidence interval, red = predicition interval")
lng

```

```{r}
####Produce a point estimate and associated 90% prediction interval for the longevity of a species whose brain weight is 800 gm. Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?
summary(m)

y = 1.218x + 248.95 = 1223.35

pi <- predict(m, newdata = data.frame(BrainSize = 800), interval = "prediction", 
    level = 0.90)  # for a single value
pi
##### 90% prediction interval: 1021.8, 1424.9

#### ln version
summary(lnm)
log(800) = 6.68
y = 0.234x + 4.88 = 6.44
  
lnpi <- predict(lnm, newdata = data.frame(lnBrainSize = log(800)), interval = "prediction", 
    level = 0.90)  # for a single value
lnpi

##### 90% prediction interval: 6.02, 6.87

##### I don't really trust the model to predict observations accurately at 800g Brain Size because the vast majority of observations are for brains less than 150g. There may be some change in the relationship between brain size and longevity at brain sizes >150g that isn't being reflected in the data collected here.
```

```{r}
####Looking at your two models, which do you think is better? Why?


```